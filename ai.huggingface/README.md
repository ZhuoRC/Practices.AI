# DeepSeek-OCR Local Deployment

# DeepSeek-OCR æœ¬åœ°éƒ¨ç½²

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/LICENSE)
[![Python](https://img.shields.io/badge/python-3.12%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.5.1-orange.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/cuda-11.8%2B-green.svg)](https://developer.nvidia.com/cuda-downloads)

Local deployment of DeepSeek-OCR with RESTful API, optimized for low VRAM GPUs (6GB+).

æœ¬åœ°éƒ¨ç½² DeepSeek-OCR å¹¶æä¾› RESTful APIï¼Œé’ˆå¯¹ä½æ˜¾å­˜ GPUï¼ˆ6GB+ï¼‰ä¼˜åŒ–ã€‚

---

## âœ¨ Features / åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **RESTful API**: Easy-to-use HTTP API / æ˜“ç”¨çš„ HTTP API
- ğŸ’¾ **Low VRAM Optimized**: Runs on GPUs with 6GB+ VRAM / åœ¨ 6GB+ æ˜¾å­˜çš„ GPU ä¸Šè¿è¡Œ
- ğŸ“ **File Upload Support**: Upload images directly / ç›´æ¥ä¸Šä¼ å›¾ç‰‡
- ğŸ”¤ **Base64 Support**: Process base64 encoded images / å¤„ç† base64 ç¼–ç çš„å›¾ç‰‡
- ğŸ’¿ **Auto-save Results**: Automatically save OCR results to files / è‡ªåŠ¨ä¿å­˜ OCR ç»“æœåˆ°æ–‡ä»¶
- ğŸŒ **Interactive Docs**: Built-in Swagger UI / å†…ç½® Swagger UI
- ğŸ”§ **GPU Diagnostics**: Built-in GPU checking tool / å†…ç½® GPU æ£€æµ‹å·¥å…·
- ğŸ“– **Bilingual Docs**: Complete Chinese & English documentation / å®Œæ•´çš„ä¸­è‹±æ–‡æ–‡æ¡£

---

## ğŸ“‹ Table of Contents / ç›®å½•

- [Quick Start / å¿«é€Ÿå¼€å§‹](#-quick-start--å¿«é€Ÿå¼€å§‹)
- [Requirements / ç³»ç»Ÿè¦æ±‚](#-requirements--ç³»ç»Ÿè¦æ±‚)
- [Installation / å®‰è£…](#-installation--å®‰è£…)
- [Usage / ä½¿ç”¨æ–¹æ³•](#-usage--ä½¿ç”¨æ–¹æ³•)
- [API Endpoints / API ç«¯ç‚¹](#-api-endpoints--api-ç«¯ç‚¹)
- [Examples / ç¤ºä¾‹](#-examples--ç¤ºä¾‹)
- [Documentation / æ–‡æ¡£](#-documentation--æ–‡æ¡£)
- [Troubleshooting / æ•…éšœæ’é™¤](#-troubleshooting--æ•…éšœæ’é™¤)
- [Project Structure / é¡¹ç›®ç»“æ„](#-project-structure--é¡¹ç›®ç»“æ„)
- [License / è®¸å¯è¯](#-license--è®¸å¯è¯)

---

## ğŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

Get started in 3 simple steps! / ä¸‰æ­¥å¿«é€Ÿå¼€å§‹ï¼

### 1. Install Dependencies / å®‰è£…ä¾èµ–

```bash
# Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv

# Activate / æ¿€æ´»
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install PyTorch with CUDA / å®‰è£…æ”¯æŒ CUDA çš„ PyTorch
pip install torch==2.5.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install Flash Attention / å®‰è£… Flash Attention
pip install flash-attn==2.7.3 --no-build-isolation

# Install other dependencies / å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

### 2. Verify Installation / éªŒè¯å®‰è£…

```bash
python check_gpu.py
```

### 3. Start API Server / å¯åŠ¨ API æœåŠ¡å™¨

```bash
python deepseek_ocr/deepseek_ocr_api_low_vram.py
```

**ğŸ‰ Done! API is running on / å®Œæˆï¼API è¿è¡Œåœ¨:** `http://localhost:8031`

**ğŸ“š Interactive Docs / äº¤äº’å¼æ–‡æ¡£:** `http://localhost:8031/docs`

---

## ğŸ’» Requirements / ç³»ç»Ÿè¦æ±‚

### Hardware / ç¡¬ä»¶

- **GPU**: NVIDIA GPU with 6GB+ VRAM / NVIDIA GPUï¼Œ6GB+ æ˜¾å­˜
  - Recommended / æ¨è: GTX 1660 Ti, RTX 3060, RTX 4060 or better / æˆ–æ›´å¥½
  - Minimum / æœ€ä½: GTX 1060 6GB (with optimizations) / æ­é…ä¼˜åŒ–
- **RAM**: 16GB+ system memory / 16GB+ ç³»ç»Ÿå†…å­˜
- **Disk**: 20GB+ free space / 20GB+ å¯ç”¨ç©ºé—´

### Software / è½¯ä»¶

- **OS**: Windows 10/11, Linux (Ubuntu 20.04+), macOS
- **Python**: 3.12.9+ (3.12 recommended / æ¨è 3.12)
- **CUDA**: 11.8 or 12.1
- **NVIDIA Driver**: Latest / æœ€æ–°ç‰ˆæœ¬

---

## ğŸ“¦ Installation / å®‰è£…

### Step 1: Clone or Download / å…‹éš†æˆ–ä¸‹è½½

This project is part of the `Practices.AI` monorepo:

æœ¬é¡¹ç›®æ˜¯ `Practices.AI` å•ä½“ä»“åº“çš„ä¸€éƒ¨åˆ†ï¼š

```bash
# Navigate to the project / è¿›å…¥é¡¹ç›®ç›®å½•
cd ai.huggingface
```

### Step 2: Create Virtual Environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### Step 3: Install PyTorch with CUDA / å®‰è£…æ”¯æŒ CUDA çš„ PyTorch

**Check your CUDA version first / é¦–å…ˆæ£€æŸ¥ CUDA ç‰ˆæœ¬:**

```bash
nvidia-smi
```

**Install PyTorch / å®‰è£… PyTorch:**

```bash
# For CUDA 12.1 / é€‚ç”¨äº CUDA 12.1
pip install torch==2.5.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# For CUDA 11.8 / é€‚ç”¨äº CUDA 11.8
pip install torch==2.5.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Step 4: Install Flash Attention / å®‰è£… Flash Attention

**âš ï¸ IMPORTANT / é‡è¦**: This is **required** for DeepSeek-OCR!

è¿™æ˜¯ DeepSeek-OCR çš„**å¿…éœ€**ç»„ä»¶ï¼

```bash
pip install flash-attn==2.7.3 --no-build-isolation
```

**Note / æ³¨æ„**: This may take 5-10 minutes to compile.

ç¼–è¯‘å¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿã€‚

### Step 5: Install Other Dependencies / å®‰è£…å…¶ä»–ä¾èµ–

```bash
pip install -r requirements.txt
```

### Step 6: Verify Installation / éªŒè¯å®‰è£…

```bash
python check_gpu.py
```

**Expected output / æœŸæœ›è¾“å‡º:**

```
[OK] GPU environment is properly configured!
[OK] DeepSeek-OCR is ready to run
```

---

## ğŸ¯ Usage / ä½¿ç”¨æ–¹æ³•

### Start the API Server / å¯åŠ¨ API æœåŠ¡å™¨

```bash
python deepseek_ocr/deepseek_ocr_api_low_vram.py
```

The server will start on `http://localhost:8031`

æœåŠ¡å™¨å°†åœ¨ `http://localhost:8031` å¯åŠ¨

### Using the API / ä½¿ç”¨ API

#### Method 1: Web Browser (Interactive Docs) / æ–¹æ³• 1: æµè§ˆå™¨ï¼ˆäº¤äº’å¼æ–‡æ¡£ï¼‰

Navigate to `http://localhost:8031/docs` for interactive API documentation.

è®¿é—® `http://localhost:8031/docs` æŸ¥çœ‹äº¤äº’å¼ API æ–‡æ¡£ã€‚

#### Method 2: cURL

```bash
# Health check / å¥åº·æ£€æŸ¥
curl http://localhost:8031/health

# OCR from file / æ–‡ä»¶ OCR
curl -X POST http://localhost:8031/ocr \
  -F "image=@document.png" \
  -F "save_to_file=true"
```

#### Method 3: Python

```python
import requests

# Perform OCR / æ‰§è¡Œ OCR
with open("document.png", "rb") as f:
    files = {"image": f}
    response = requests.post("http://localhost:8031/ocr", files=files)
    result = response.json()
    print(result["text"])
```

See [API Usage Guide](docs/API_USAGE.md) for complete examples.

å®Œæ•´ç¤ºä¾‹è§ [API ä½¿ç”¨æŒ‡å—](docs/API_USAGE.md)ã€‚

---

## ğŸ”Œ API Endpoints / API ç«¯ç‚¹

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information / API ä¿¡æ¯ |
| `/health` | GET | Health check with GPU stats / å¥åº·æ£€æŸ¥å’Œ GPU ç»Ÿè®¡ |
| `/ocr` | POST | OCR from uploaded file / ä¸Šä¼ æ–‡ä»¶è¿›è¡Œ OCR |
| `/ocr-base64` | POST | OCR from base64 image / Base64 å›¾ç‰‡ OCR |
| `/results/{filename}` | GET | Download saved result / ä¸‹è½½ä¿å­˜çš„ç»“æœ |
| `/cleanup` | POST | Force GPU memory cleanup / å¼ºåˆ¶æ¸…ç† GPU å†…å­˜ |
| `/docs` | GET | Interactive API docs (Swagger) / äº¤äº’å¼ API æ–‡æ¡£ |

---

## ğŸ“ Examples / ç¤ºä¾‹

### Python Example / Python ç¤ºä¾‹

```python
import requests

def ocr_image(image_path):
    """
    Perform OCR on an image
    å¯¹å›¾ç‰‡æ‰§è¡Œ OCR
    """
    url = "http://localhost:8031/ocr"

    with open(image_path, "rb") as f:
        files = {"image": f}
        data = {
            "prompt": "<image>\nFree OCR.",
            "save_to_file": True
        }

        response = requests.post(url, files=files, data=data)

        if response.status_code == 200:
            result = response.json()
            print("âœ“ OCR Success!")
            print(f"Text: {result['text']}")
            print(f"Saved to: {result['output_file']}")
            return result
        else:
            print(f"âœ— Error: {response.status_code}")
            print(response.json())
            return None

# Usage / ä½¿ç”¨
result = ocr_image("document.png")
```

### JavaScript Example / JavaScript ç¤ºä¾‹

```javascript
const axios = require('axios');
const FormData = require('form-data');
const fs = require('fs');

async function ocrImage(imagePath) {
    const form = new FormData();
    form.append('image', fs.createReadStream(imagePath));
    form.append('save_to_file', 'true');

    const response = await axios.post(
        'http://localhost:8031/ocr',
        form,
        { headers: form.getHeaders() }
    );

    console.log('Text:', response.data.text);
    return response.data;
}

ocrImage('document.png');
```

### cURL Example / cURL ç¤ºä¾‹

```bash
# Basic OCR / åŸºç¡€ OCR
curl -X POST http://localhost:8031/ocr \
  -F "image=@document.png"

# With custom prompt / ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
curl -X POST http://localhost:8031/ocr \
  -F "image=@document.png" \
  -F "prompt=<image>\nConvert document to markdown"

# Download result / ä¸‹è½½ç»“æœ
curl http://localhost:8031/results/ocr_result_20250127_143022.txt -o result.txt
```

---

## ğŸ“š Documentation / æ–‡æ¡£

Complete documentation is available in the `docs/` directory:

å®Œæ•´æ–‡æ¡£ä½äº `docs/` ç›®å½•ï¼š

- **[Quick Start Guide / å¿«é€Ÿå¼€å§‹æŒ‡å—](docs/QUICK_START.md)**: Get started in 3 steps / ä¸‰æ­¥å¿«é€Ÿå¼€å§‹
- **[API Usage Guide / API ä½¿ç”¨æŒ‡å—](docs/API_USAGE.md)**: Complete API reference with examples / å®Œæ•´çš„ API å‚è€ƒå’Œç¤ºä¾‹
- **[Low VRAM Guide / ä½æ˜¾å­˜æŒ‡å—](docs/LOW_VRAM_GUIDE.md)**: Optimization tips for 6GB GPUs / 6GB GPU ä¼˜åŒ–æŠ€å·§

---

## ğŸ”§ Troubleshooting / æ•…éšœæ’é™¤

### Common Issues / å¸¸è§é—®é¢˜

#### Issue 1: CUDA Out of Memory / é—®é¢˜ 1: CUDA å†…å­˜ä¸è¶³

**Error / é”™è¯¯:**
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**Solution / è§£å†³æ–¹æ¡ˆ:**
1. Close other GPU applications / å…³é—­å…¶ä»– GPU åº”ç”¨ç¨‹åº
2. Reduce image size / å‡å°å›¾ç‰‡å°ºå¯¸
3. Use the cleanup endpoint: `curl -X POST http://localhost:8031/cleanup`
4. See [Low VRAM Guide](docs/LOW_VRAM_GUIDE.md) / æŸ¥çœ‹[ä½æ˜¾å­˜æŒ‡å—](docs/LOW_VRAM_GUIDE.md)

#### Issue 2: Flash Attention Not Found / é—®é¢˜ 2: Flash Attention æœªæ‰¾åˆ°

**Error / é”™è¯¯:**
```
ModuleNotFoundError: No module named 'flash_attn'
```

**Solution / è§£å†³æ–¹æ¡ˆ:**
```bash
pip install flash-attn==2.7.3 --no-build-isolation
```

#### Issue 3: Model Not Loading / é—®é¢˜ 3: æ¨¡å‹æœªåŠ è½½

**Error / é”™è¯¯:**
```
503 Service Unavailable: Model not loaded
```

**Solution / è§£å†³æ–¹æ¡ˆ:**
1. Check server logs for errors / æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—ä¸­çš„é”™è¯¯
2. Run `python check_gpu.py` / è¿è¡Œ `python check_gpu.py`
3. Verify all dependencies are installed / éªŒè¯æ‰€æœ‰ä¾èµ–å·²å®‰è£…
4. Restart the server / é‡å¯æœåŠ¡å™¨

### Getting Help / è·å–å¸®åŠ©

1. **Check the logs / æ£€æŸ¥æ—¥å¿—**: The server prints detailed logs
2. **Run diagnostics / è¿è¡Œè¯Šæ–­**: `python check_gpu.py`
3. **Check GPU status / æ£€æŸ¥ GPU çŠ¶æ€**: `nvidia-smi`
4. **Read the guides / é˜…è¯»æŒ‡å—**: See [Documentation](#-documentation--æ–‡æ¡£)

---

## ğŸ“ Project Structure / é¡¹ç›®ç»“æ„

```
ai.huggingface/
â”œâ”€â”€ .venv/                          # Virtual environment / è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ check_gpu.py                    # GPU diagnostics tool / GPU è¯Šæ–­å·¥å…·
â”œâ”€â”€ requirements.txt                # Python dependencies / Python ä¾èµ–
â”œâ”€â”€ README.md                       # This file / æœ¬æ–‡ä»¶
â”œâ”€â”€ docs/                           # Documentation / æ–‡æ¡£
â”‚   â”œâ”€â”€ API_USAGE.md               # API usage guide / API ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ QUICK_START.md             # Quick start guide / å¿«é€Ÿå¼€å§‹æŒ‡å—
â”‚   â””â”€â”€ LOW_VRAM_GUIDE.md          # Low VRAM optimization / ä½æ˜¾å­˜ä¼˜åŒ–
â””â”€â”€ deepseek_ocr/                  # OCR module / OCR æ¨¡å—
    â”œâ”€â”€ input/                     # Input images / è¾“å…¥å›¾ç‰‡
    â”œâ”€â”€ output/                    # OCR results / OCR ç»“æœ
    â””â”€â”€ deepseek_ocr_api_low_vram.py  # API server (Low VRAM) / API æœåŠ¡å™¨ï¼ˆä½æ˜¾å­˜ï¼‰
```

---

## ğŸ¨ Features in Detail / åŠŸèƒ½è¯¦è§£

### Memory Optimizations / å†…å­˜ä¼˜åŒ–

The API includes several built-in optimizations:

API åŒ…å«å¤šé¡¹å†…ç½®ä¼˜åŒ–ï¼š

- âœ… **torch.bfloat16**: 50% memory reduction / å‡å°‘ 50% å†…å­˜
- âœ… **Flash Attention 2**: 30% memory reduction / å‡å°‘ 30% å†…å­˜
- âœ… **Inference mode**: No gradient computation / æ— æ¢¯åº¦è®¡ç®—
- âœ… **Automatic cleanup**: Clears CUDA cache after each request / æ¯æ¬¡è¯·æ±‚åæ¸…ç† CUDA ç¼“å­˜

### Input Formats / è¾“å…¥æ ¼å¼

Supports multiple input methods:

æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼š

- ğŸ“¤ **File upload**: Upload images directly via multipart/form-data / é€šè¿‡ multipart/form-data ç›´æ¥ä¸Šä¼ å›¾ç‰‡
- ğŸ“‹ **Base64**: Send base64 encoded images / å‘é€ base64 ç¼–ç çš„å›¾ç‰‡
- ğŸ–¼ï¸ **Image formats**: PNG, JPG, JPEG, etc. / PNGã€JPGã€JPEG ç­‰

### Output Options / è¾“å‡ºé€‰é¡¹

Flexible output handling:

çµæ´»çš„è¾“å‡ºå¤„ç†ï¼š

- ğŸ“„ **JSON response**: Get text in API response / åœ¨ API å“åº”ä¸­è·å–æ–‡æœ¬
- ğŸ’¾ **Auto-save**: Automatically save results to files / è‡ªåŠ¨ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
- ğŸ“¥ **File download**: Download saved results via API / é€šè¿‡ API ä¸‹è½½ä¿å­˜çš„ç»“æœ

---

## ğŸŒŸ Model Information / æ¨¡å‹ä¿¡æ¯

- **Model / æ¨¡å‹**: [deepseek-ai/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- **Parameters / å‚æ•°**: 3B (3 billion / 30 äº¿)
- **License / è®¸å¯è¯**: MIT
- **Task / ä»»åŠ¡**: Optical Character Recognition (OCR) / å…‰å­¦å­—ç¬¦è¯†åˆ«
- **Features / ç‰¹æ€§**:
  - Text extraction / æ–‡æœ¬æå–
  - Markdown conversion / Markdown è½¬æ¢
  - Multi-language support / å¤šè¯­è¨€æ”¯æŒ

---

## ğŸ¤ Contributing / è´¡çŒ®

Contributions are welcome! / æ¬¢è¿è´¡çŒ®ï¼

1. Fork the repository / Fork ä»“åº“
2. Create your feature branch / åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. Commit your changes / æäº¤æ›´æ”¹
4. Push to the branch / æ¨é€åˆ°åˆ†æ”¯
5. Open a Pull Request / æ‰“å¼€ Pull Request

---

## ğŸ“„ License / è®¸å¯è¯

This project is licensed under the MIT License.

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

The DeepSeek-OCR model is licensed under the MIT License by DeepSeek AI.

DeepSeek-OCR æ¨¡å‹ç”± DeepSeek AI é‡‡ç”¨ MIT è®¸å¯è¯æˆæƒã€‚

---

## ğŸ™ Acknowledgments / è‡´è°¢

- [DeepSeek AI](https://www.deepseek.com/) for the DeepSeek-OCR model / æä¾› DeepSeek-OCR æ¨¡å‹
- [Hugging Face](https://huggingface.co/) for model hosting / æä¾›æ¨¡å‹æ‰˜ç®¡
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework / æä¾› Web æ¡†æ¶
- [PyTorch](https://pytorch.org/) for the deep learning framework / æä¾›æ·±åº¦å­¦ä¹ æ¡†æ¶

---

## ğŸ“ Support / æ”¯æŒ

- **Documentation / æ–‡æ¡£**: See [docs/](docs/) directory / æŸ¥çœ‹ [docs/](docs/) ç›®å½•
- **Issues / é—®é¢˜**: Check [Troubleshooting](#-troubleshooting--æ•…éšœæ’é™¤) section / æŸ¥çœ‹[æ•…éšœæ’é™¤](#-troubleshooting--æ•…éšœæ’é™¤)éƒ¨åˆ†
- **Model Info / æ¨¡å‹ä¿¡æ¯**: [HuggingFace Model Page](https://huggingface.co/deepseek-ai/DeepSeek-OCR)

---

**Made with â¤ï¸ for the AI community**

**ä¸º AI ç¤¾åŒºç”¨å¿ƒåˆ¶ä½œ**

---

**Quick Links / å¿«é€Ÿé“¾æ¥:**

- ğŸ“– [Quick Start / å¿«é€Ÿå¼€å§‹](docs/QUICK_START.md)
- ğŸ“š [API Documentation / API æ–‡æ¡£](docs/API_USAGE.md)
- ğŸ”§ [Low VRAM Guide / ä½æ˜¾å­˜æŒ‡å—](docs/LOW_VRAM_GUIDE.md)
- ğŸŒ [Interactive API Docs / äº¤äº’å¼ API æ–‡æ¡£](http://localhost:8031/docs) (when server is running / æœåŠ¡å™¨è¿è¡Œæ—¶)
