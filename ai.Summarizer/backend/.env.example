# LLM Configuration
LLM_PROVIDER=cloud  # "cloud" or "local"

# Cloud API Configuration (Qwen)
QWEN_API_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_API_KEY=your_api_key_here
QWEN_MODEL=qwen-turbo

# Ollama Configuration (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b-instruct

# Server Configuration
HOST=0.0.0.0
PORT=8002

# Document Storage
DOCUMENT_STORAGE_PATH=../data/documents

# Chunking Configuration
# Larger chunks = fewer API calls = faster processing
# Recommended: 2000-3000 for faster performance, 800-1200 for more detailed summaries
MIN_CHUNK_SIZE=2000
MAX_CHUNK_SIZE=3000
CHUNK_OVERLAP=200

# Audio/Video Transcription Configuration
# Whisper model size: tiny, base, small, medium, large
# Larger models = better accuracy but slower processing and more memory
# Recommended: base (balanced) or small (faster)
WHISPER_MODEL=small

# Maximum file size for audio/video uploads (in bytes)
# 100MB = 100000000 bytes
MAX_AUDIO_FILE_SIZE=100000000

# Maximum audio duration (in seconds)
# 3600 seconds = 1 hour
MAX_AUDIO_DURATION=3600
