# LLM Configuration
LLM_PROVIDER=cloud  # "cloud" or "local"

# Cloud API Configuration (Qwen)
QWEN_API_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_API_KEY=your_api_key_here
QWEN_MODEL=qwen-turbo

# Ollama Configuration (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b-instruct

# Server Configuration
HOST=0.0.0.0
PORT=8002

# Document Storage
DOCUMENT_STORAGE_PATH=../data/documents

# Chunking Configuration
# Larger chunks = fewer API calls = faster processing
# Recommended: 2000-3000 for faster performance, 800-1200 for more detailed summaries
MIN_CHUNK_SIZE=2000
MAX_CHUNK_SIZE=3000
CHUNK_OVERLAP=200
